{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10676c91",
   "metadata": {},
   "source": [
    "# Assignment 3: Convolutional Neural Networks (50 marks total)\n",
    "### Due: October 17 at 11:59pm\n",
    "\n",
    "### Name: Hiu Sum Yuen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4ae81",
   "metadata": {},
   "source": [
    "The goal of this assignment is to apply Convolutional Neural Networks (CNNs) in PyTorch for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66939dd",
   "metadata": {},
   "source": [
    "## Part 1: MLP vs. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9fd67",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f7209",
   "metadata": {},
   "source": [
    "### Step 1: Data Loading & Preprocessing (11 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a00aa",
   "metadata": {},
   "source": [
    "This assignment will use the CIFAR-10 dataset (*available via torchvision.datasets*). CIFAR-10 is a smaller version of the ImageNet dataset, that contains 60,000 32Ã—32 color images in 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09289a88",
   "metadata": {},
   "source": [
    "The first step is to define the transformations for the training and testing datasets. In this case, we will apply a random horizontal flip. Apply any other transformations that are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define transforms for train and test sets (2 marks)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22cead9",
   "metadata": {},
   "source": [
    "The next step is to load the training and testing datasets and split the training data into training and validation sets. You can consider 20% of the training dataset will be used for validation. You can use a batch size of 64 for all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f000cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load Datasets (1 mark)\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                           download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                          download=True, transform=transform_test)\n",
    "\n",
    "# TODO: Split train into train + validation (1 mark)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# TODO: Data loaders (1 mark)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59d177",
   "metadata": {},
   "source": [
    "For this assignment, we will compare the performance of a feed-forward network (MLP) with a convolutional neural network (CNN). We will need to define a separate class to represent each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab667750",
   "metadata": {},
   "source": [
    "Your MLP class should have the following minimum requirements:\n",
    "- At least 3 layers with ReLU activations\n",
    "- At least 500 hidden units per layer\n",
    "- Softmax output layer for 10 classes\n",
    "\n",
    "Print a summary of the model architecture (number of parameters, layer shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f72ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define Neural Network Model (3 marks)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)  # Flatten the image\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Create model and print summary\n",
    "mlp_model = MLP().to(device)\n",
    "print(\"MLP Model Summary:\")\n",
    "print(mlp_model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in mlp_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31beb479",
   "metadata": {},
   "source": [
    "Your CNN class should have the following minimum requirements:\n",
    "- At least 3 convolutional layers with ReLU activations\n",
    "  - Example output for 3 layers: 32 feature maps -> 64 feature maps -> 128 feature maps\n",
    "- At least 2 max-pooling layers\n",
    "- At least 1 fully connected layer before the output\n",
    "- Softmax output layer for 10 classes\n",
    "- Use dropout to improve generalization\n",
    "\n",
    "Print a summary of the model architecture (number of parameters, layer shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define CNN Model (3 marks)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Create model and print summary\n",
    "cnn_model = CNN().to(device)\n",
    "print(\"CNN Model Summary:\")\n",
    "print(cnn_model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in cnn_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8641467",
   "metadata": {},
   "source": [
    "### Step 3: Define Training and Testing Loops (7 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051e648",
   "metadata": {},
   "source": [
    "Next, you will need to define the loss criterion and the optimizer. Select an appropriate criterion. For the optimizer, use Adam with a constant learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define loss criterion and optimizer (2 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba18a73",
   "metadata": {},
   "source": [
    "Since we are evaluating the performance of two different models, we can create functions for both the training and validation loops. For each loop, you should print the average loss and the accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training loop (3 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc985649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validation loop (2 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d222a",
   "metadata": {},
   "source": [
    "### Step 4: Train, Evaluate and Visualize (11 marks)\n",
    "\n",
    "We can also create functions for plotting the training and validation losses over the epochs and for creating a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create plotting functions (2 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5c7c0c",
   "metadata": {},
   "source": [
    "Now that we have defined our required functions, we can train, evaluate and visualize the results for both models. You can use 20 epochs for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08120f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run Training and validation loops for NN (2 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot losses for NN (1 mark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run Training and validation loops for CNN (2 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot losses for CNN (1 mark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903acc7d",
   "metadata": {},
   "source": [
    "### Step 5: Model Testing (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2013d9",
   "metadata": {},
   "source": [
    "Now that we have compared the two models, we can select the best one and use the testing data to see how well this model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test loop (3 marks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f6447",
   "metadata": {},
   "source": [
    "### Questions (12 marks)\n",
    "1. How do your training, validation, and test accuracies compare for your best model? What does this tell you about the model's generalization?\n",
    "1. Examine your results for both models. Do you see signs of overfitting or underfitting? Explain what indicates this.\n",
    "1. How can we further improve the results? Provide two suggestions.\n",
    "1. If your model performs poorly on certain classes (check your confusion matrix), what does that suggest about those images or their features?\n",
    "1. What is the role of dropout in the CNN? How might removing dropout change your results?\n",
    "1. What other data transformations did you include and why? Are there any other data augmentation methods that we could use for this dataset?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce0016",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571beb00",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE - BE SPECIFIC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc61de",
   "metadata": {},
   "source": [
    "## Part 2: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d544c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
